Resourses of attention in deep learning.

https://www.quora.com/What-is-exactly-the-attention-mechanism-introduced-to-RNN-recurrent-neural-network-It-would-be-nice-if-you-could-make-it-easy-to-understand

https://distill.pub/2016/augmented-rnns/

https://www.quora.com/What-is-Attention-Mechanism-in-Neural-Networks

https://www.quora.com/What-is-attention-in-the-context-of-deep-learning

https://danvatterott.com/blog/2016/09/20/attention-in-a-convolutional-neural-net/


https://www.zhihu.com/search?type=content&q=attention

https://www.zhihu.com/question/36591394
值得反复看

https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-3/

https://zhuanlan.zhihu.com/p/22081325
浅显易懂

https://zhuanlan.zhihu.com/p/25928551
写得不错，调参的经验很好

https://zhuanlan.zhihu.com/p/28054589
很浅显


attention is all your need

https://www.zhihu.com/question/61077555

https://zhuanlan.zhihu.com/p/27600655


Fairseq
https://www.zhihu.com/question/59645329




