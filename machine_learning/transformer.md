

https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)

https://towardsdatascience.com/transformers-141e32e69591

https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html

[When Recurrent Models Don't Need to be Recurrent](https://bair.berkeley.edu/blog/2018/08/06/recurrent/)

https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html


https://zhuanlan.zhihu.com/p/48508221

https://zhuanlan.zhihu.com/p/47282410

http://jalammar.github.io/illustrated-transformer/

这三篇差不多，讲的都很好

https://zhuanlan.zhihu.com/p/38485843

挺好，可再看

https://zhuanlan.zhihu.com/p/47812375

https://www.zhihu.com/question/302392659/answer/551542493

https://www.zhihu.com/question/311377593/answer/591236505

https://zhuanlan.zhihu.com/p/48731949

https://www.zhihu.com/question/313507574/answer/645129386

https://zhuanlan.zhihu.com/p/52924578

https://zhuanlan.zhihu.com/p/59629215

https://zhuanlan.zhihu.com/p/39034683

https://zhuanlan.zhihu.com/p/54356280




https://zhuanlan.zhihu.com/p/54770086




https://ricardokleinklein.github.io/2017/11/16/Attention-is-all-you-need.html

https://medium.com/@adityathiruvengadam/transformer-architecture-attention-is-all-you-need-aeccd9f50d09

